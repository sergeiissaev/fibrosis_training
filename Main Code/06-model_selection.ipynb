{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning to Quantify Fibrosis in Muscle Tissue\n",
    "## Model Selection\n",
    "## By Sergei Issaev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'aug18ep150'\n",
    "test_file = '/home/sergei/projects/def-rogertam/sergei/micro_scans/data/traintest/diaphragmsmarinefascia4/validation_finalxxx.npz'\n",
    "training_data_directory = '/home/sergei/projects/def-rogertam/sergei/micro_scans/data/traintest/diaphragmsmarinefascia4/train_finalxxx.npz'\n",
    "model_run = f'/home/sergei/projects/def-rogertam/sergei/micro_scans/models/{run}/'\n",
    "epochs = 150\n",
    "print(f\"Welcome to the evaluation for the run conducted on {run}! I hope you are happy with the results!\")\n",
    "inv_data_gen_args = dict()\n",
    "# , samplewise_center=True\n",
    "# load image data\n",
    "\n",
    "# load and prepare training images\n",
    "from numpy import load\n",
    "def load_real_samples(filename):\n",
    "    # load compressed arrays\n",
    "    data = load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n",
    "\n",
    "seed = 12\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Edit Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy import load\n",
    "from numpy import vstack\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randint\n",
    "import cv2  \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(1, '/project/def-rogertam/sergei/micro_scans/code_files/product')\n",
    "import threshold_fx\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "corrs = []\n",
    "abso = []\n",
    "real = []\n",
    "invariant_datagen = ImageDataGenerator(**inv_data_gen_args)\n",
    "\n",
    "dataset = load_real_samples(training_data_directory)\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "trainA, trainB = dataset\n",
    "invariant_datagen.fit(trainA, augment=True, seed=seed)\n",
    "\n",
    "data = load(test_file)\n",
    "[A1, A2] = data['arr_0'], data['arr_1'] \n",
    "X1 = (A1 - 127.5) / 127.5\n",
    "X2 = (A2 - 127.5) / 127.5\n",
    "print('Loaded a test set of shape', X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in tqdm(range(0, 10)):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    model = load_model(model_run + 'model_00' + str(x) + '000.h5', compile=False)\n",
    "    #print(f'using model {x}\\nThe test shape is of size {X1.shape}.')\n",
    "    for l in range(X1.shape[0] // 2):\n",
    "        #print('*' * 30)\n",
    "        #print(f'Starting {l}')\n",
    "        src_image, tar_image = X1[[l]], X2[[l]]\n",
    "        invariant_generator = invariant_datagen.flow(\n",
    "        src_image,\n",
    "        seed=seed)\n",
    "        invariant_generator.next()\n",
    "        \n",
    "        \n",
    "        invariant =  invariant_generator[0].copy()\n",
    " \n",
    "        src_image = invariant        \n",
    "        \n",
    "        gen_image = model.predict(src_image)\n",
    "        gen = (gen_image + abs(gen_image.min())) / 2.0\n",
    "\n",
    "        white, black, thresh1 = threshold_fx.threshold_fx(A1, l, 0)\n",
    "        if white != 0:\n",
    "            gen_calc, threshgen = threshold_fx.threshold_gen(gen, white)\n",
    "            true_calc, threshtar = threshold_fx.threshold_gen(tar_image, white)\n",
    "        else:\n",
    "            gen_calc = 0\n",
    "            true_calc = 0\n",
    "            threshgen = np.zeros((thresh1.shape))\n",
    "            threshtar = np.zeros((thresh1.shape))\n",
    "        \n",
    "      #  srcs = (cv2.cvtColor(src_image.squeeze(), cv2.COLOR_BGR2RGB))\n",
    "      #  num = random.randint(1, 100)\n",
    "        #print(f\"num is {num}\")\n",
    "       # if num > 90:\n",
    "      #      srcs = srcs + 1.0 / 2.0\n",
    "      #      print(srcs.max(), srcs.min())\n",
    "       #     plt.imshow(srcs)\n",
    "       #     plt.title('Source')\n",
    "       #     plt.show()\n",
    "        #    plt.imshow(thresh1, cmap='gray')\n",
    "       #     plt.title(f'Threshold={white}')\n",
    "      #      plt.show()\n",
    "      #      plt.imshow(threshgen, cmap='gray')\n",
    "       #     plt.title(f'Generated={gen_calc}')\n",
    "       #     plt.show()\n",
    "       #     plt.imshow(threshtar, cmap='gray')\n",
    "       #     plt.title(f'Ground Truth={true_calc}')\n",
    "        #   plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        l1.append(gen_calc)\n",
    "        l2.append(true_calc )\n",
    "\n",
    "        \n",
    "    #print('$' * 1000)\n",
    "    diff = 0\n",
    "    for i in range(len(l1)):\n",
    "        diff += abs(l1[i] - l2[i])\n",
    "    diffr = 0\n",
    "    for i in range(len(l1)):\n",
    "        diffr += (l1[i] - l2[i])\n",
    "    correlation, p_value = stats.pearsonr(l1, l2)\n",
    "    corrs.append(correlation)\n",
    "    abso.append(diff)\n",
    "    real.append(diffr)\n",
    "    #print(f'Diff = {diff}')\n",
    "    #print(f'Diffr = {diffr}')\n",
    "   # print(f'Correlation = {correlation}')\n",
    "print('Done the first 10!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(range(10, 100)):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    model = load_model(model_run + 'model_0' + str(x) + '000.h5', compile=False)\n",
    "   # print(f'using model {x}\\nThe test shape is of size {X1.shape}.')\n",
    "\n",
    "    for l in range(X1.shape[0] // 2):\n",
    "        #print('*' * 30)\n",
    "        #print(f'Starting {l}')\n",
    "        src_image, tar_image = X1[[l]], X2[[l]]\n",
    "        invariant_generator = invariant_datagen.flow(\n",
    "        src_image,\n",
    "        seed=seed)\n",
    "        invariant_generator.next()\n",
    "        \n",
    "        \n",
    "        invariant =  invariant_generator[0].copy()\n",
    " \n",
    "        src_image = invariant      \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        gen_image = model.predict(src_image)\n",
    "        gen = (gen_image + abs(gen_image.min())) / 2.0\n",
    "\n",
    "        white, black, thresh1 = threshold_fx.threshold_fx(A1, l, 0)\n",
    "        if white != 0:\n",
    "            gen_calc, threshgen = threshold_fx.threshold_gen(gen, white)\n",
    "            true_calc, threshtar = threshold_fx.threshold_gen(tar_image, white)\n",
    "        else:\n",
    "            gen_calc = 0\n",
    "            true_calc = 0\n",
    "            threshgen = np.zeros((thresh1.shape))\n",
    "            threshtar = np.zeros((thresh1.shape))\n",
    "        \n",
    "        srcs = (cv2.cvtColor(src_image.squeeze(), cv2.COLOR_BGR2RGB))\n",
    "        num = random.randint(1, 100)\n",
    "        #print(f\"num is {num}\")\n",
    "      #  if num > 90:\n",
    "      #      srcs = srcs + 1.0 / 2.0\n",
    "      #      print(srcs.max(), srcs.min())\n",
    "       #     plt.imshow(srcs)\n",
    "       #     plt.title('Source')\n",
    "      #      plt.show()\n",
    "     #       plt.imshow(thresh1, cmap='gray')\n",
    "      #      plt.title(f'Threshold={white}')\n",
    "       #     plt.show()\n",
    "      #      plt.imshow(threshgen, cmap='gray')\n",
    "     #       plt.title(f'Generated={gen_calc}')\n",
    "       #     plt.show()\n",
    "      #      plt.imshow(threshtar, cmap='gray')\n",
    "       #     plt.title(f'Ground Truth={true_calc}')\n",
    "       #     plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        l1.append(gen_calc)\n",
    "        l2.append(true_calc )\n",
    "\n",
    "        \n",
    "   # print('$' * 1000)\n",
    "    diff = 0\n",
    "    for i in range(len(l1)):\n",
    "        diff += abs(l1[i] - l2[i])\n",
    "    diffr = 0\n",
    "    for i in range(len(l1)):\n",
    "        diffr += (l1[i] - l2[i])\n",
    "    correlation, p_value = stats.pearsonr(l1, l2)\n",
    "    corrs.append(correlation)\n",
    "    abso.append(diff)\n",
    "    real.append(diffr)\n",
    "    #print(f'Diff = {diff}')\n",
    "    #print(f'Diffr = {diffr}')\n",
    "   # print(f'Correlation = {correlation}')\n",
    "print('Thanks for waiting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(range(100, 228)):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    model = load_model(model_run + 'model_' + str(x) + '000.h5', compile=False)\n",
    "   # print(f'using model {x}\\nThe test shape is of size {X1.shape}.')\n",
    "\n",
    "    for l in range(X1.shape[0] // 2):\n",
    "        #print('*' * 30)\n",
    "        #print(f'Starting {l}')\n",
    "        src_image, tar_image = X1[[l]], X2[[l]]\n",
    "        invariant_generator = invariant_datagen.flow(\n",
    "        src_image,\n",
    "        seed=seed)\n",
    "        invariant_generator.next()\n",
    "        \n",
    "        \n",
    "        invariant =  invariant_generator[0].copy()\n",
    " \n",
    "        src_image = invariant      \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        gen_image = model.predict(src_image)\n",
    "        gen = (gen_image + abs(gen_image.min())) / 2.0\n",
    "\n",
    "        white, black, thresh1 = threshold_fx.threshold_fx(A1, l, 0)\n",
    "        if white != 0:\n",
    "            gen_calc, threshgen = threshold_fx.threshold_gen(gen, white)\n",
    "            true_calc, threshtar = threshold_fx.threshold_gen(tar_image, white)\n",
    "        else:\n",
    "            gen_calc = 0\n",
    "            true_calc = 0\n",
    "            threshgen = np.zeros((thresh1.shape))\n",
    "            threshtar = np.zeros((thresh1.shape))\n",
    "        \n",
    "        srcs = (cv2.cvtColor(src_image.squeeze(), cv2.COLOR_BGR2RGB))\n",
    "        num = random.randint(1, 100)\n",
    "        #print(f\"num is {num}\")\n",
    "      #  if num > 90:\n",
    "      #      srcs = srcs + 1.0 / 2.0\n",
    "      #      print(srcs.max(), srcs.min())\n",
    "       #     plt.imshow(srcs)\n",
    "       #     plt.title('Source')\n",
    "      #      plt.show()\n",
    "     #       plt.imshow(thresh1, cmap='gray')\n",
    "      #      plt.title(f'Threshold={white}')\n",
    "       #     plt.show()\n",
    "      #      plt.imshow(threshgen, cmap='gray')\n",
    "     #       plt.title(f'Generated={gen_calc}')\n",
    "       #     plt.show()\n",
    "      #      plt.imshow(threshtar, cmap='gray')\n",
    "       #     plt.title(f'Ground Truth={true_calc}')\n",
    "       #     plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        l1.append(gen_calc)\n",
    "        l2.append(true_calc )\n",
    "\n",
    "        \n",
    "   # print('$' * 1000)\n",
    "    diff = 0\n",
    "    for i in range(len(l1)):\n",
    "        diff += abs(l1[i] - l2[i])\n",
    "    diffr = 0\n",
    "    for i in range(len(l1)):\n",
    "        diffr += (l1[i] - l2[i])\n",
    "    correlation, p_value = stats.pearsonr(l1, l2)\n",
    "\n",
    "    corrs.append(correlation)\n",
    "    abso.append(diff)\n",
    "    real.append(diffr)\n",
    "    #print(f'Diff = {diff}')\n",
    "    #print(f'Diffr = {diffr}')\n",
    "   # print(f'Correlation = {correlation}')\n",
    "\n",
    "print(\"Smile more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print('@' * 50)\n",
    "print(\"Here is what the results are:\")\n",
    "print(f'The original corrs is {corrs}. The correlation of l1 and l2 for the nth weight file is in the nth position of this run.')\n",
    "cor = sorted(corrs)\n",
    "print(f'We sort it to get {cor}. This is the sorted version. Check out the end to see the best correlation!')\n",
    "positionscor = []\n",
    "for x in range(len(cor)):\n",
    "    positionscor.append(corrs.index(cor[x]))\n",
    "print(f'The following list shows which model occupies which spot in the sorted list of correlations. The end of the list is the best model! positionscor is {positionscor}.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original abso is {abso}')\n",
    "ab = sorted(abso)\n",
    "print(f'We sort it to get {ab}')\n",
    "positionsabs = []\n",
    "for x in range(len(ab)):\n",
    "    positionsabs.append(abso.index(ab[x]))\n",
    "positionsabs.reverse()\n",
    "print(f'positionsabs is {positionsabs}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('$' * 50)\n",
    "finals = list()\n",
    "number_models = len(ab)\n",
    "for k in range(len(ab)):\n",
    "    corspot = (positionscor.index(k) + 1)/ number_models\n",
    "    try:\n",
    "        absspot = (positionsabs.index(k) + 1)/ number_models\n",
    "        metric = 0.5 * corspot + 0.5 * absspot \n",
    "        finals.append(metric)\n",
    "        print(f'the model is {k}, it holds position {positionscor.index(k)} in positionscor / {number_models} = {corspot}, and position {positionsabs.index(k)} in positionsabs / {number_models} = {absspot}. We weigh this as {0.5 * corspot} + {0.5 * absspot} = {metric}')\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "    print(f'Finals is {finals}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_finals = sorted(finals)\n",
    "print(f\"Sorted finals is {sorted_finals}\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(f'The best model is {finals.index(sorted_finals[-1])}, followed by {finals.index(sorted_finals[-2])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in tqdm(range(0,10)):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    model = load_model(model_run + 'model_00' + str(x) + '000.h5', compile=False)\n",
    "    print(f'using model {x}\\nThe test shape is of size {X1.shape}.')\n",
    "    for l in range(X1.shape[0]):\n",
    "        print('*' * 30)\n",
    "        print(f'Starting {l}')\n",
    "        src_image, tar_image = X1[[l]], X2[[l]]\n",
    "        gen_image = model.predict(src_image)\n",
    "        gen = (gen_image + abs(gen_image.min())) / 2.0\n",
    "\n",
    "        white, black, thresh1 = threshold_fx.threshold_fx(A1, l)\n",
    "        if white != 0:\n",
    "            gen_calc, threshgen = threshold_fx.threshold_gen(gen, white)\n",
    "            true_calc, threshtar = threshold_fx.threshold_gen(tar_image, white)\n",
    "        else:\n",
    "            gen_calc = 0\n",
    "            true_calc = 0\n",
    "            threshgen = np.zeros((thresh1.shape))\n",
    "            threshtar = np.zeros((thresh1.shape))\n",
    "        \n",
    "        srcs = (cv2.cvtColor(src_image.squeeze(), cv2.COLOR_BGR2RGB))\n",
    "        num = random.randint(1, 100)\n",
    "        #print(f\"num is {num}\")\n",
    "        if num > 90:\n",
    "            srcs = srcs + 1.0 / 2.0\n",
    "            print(srcs.max(), srcs.min())\n",
    "            plt.imshow(srcs)\n",
    "            plt.title('Source')\n",
    "            plt.show()\n",
    "            plt.imshow(thresh1, cmap='gray')\n",
    "            plt.title(f'Threshold={white}')\n",
    "            plt.show()\n",
    "            plt.imshow(threshgen, cmap='gray')\n",
    "            plt.title(f'Generated={gen_calc}')\n",
    "            plt.show()\n",
    "            plt.imshow(threshtar, cmap='gray')\n",
    "            plt.title(f'Ground Truth={true_calc}')\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        l1.append(gen_calc)\n",
    "        l2.append(true_calc)\n",
    "\n",
    "        \n",
    "    print('$' * 1000)\n",
    "    diff = 0\n",
    "    for i in range(len(l1)):\n",
    "        diff += abs(l1[i] - l2[i])\n",
    "    diffr = 0\n",
    "    for i in range(len(l1)):\n",
    "        diffr += (l1[i] - l2[i])\n",
    "    correlation, p_value = stats.pearsonr(l1, l2)\n",
    "    corrs.append(correlation)\n",
    "    abso.append(diff)\n",
    "    real.append(diffr)\n",
    "    print(f'Diff = {diff}')\n",
    "    print(f'Diffr = {diffr}')\n",
    "    print(f'Correlation = {correlation}')\n",
    "########################################################################################################################\n",
    "print('@' * 50)\n",
    "print(f'Original corrs is {corrs}')\n",
    "cor = sorted(corrs)\n",
    "print(f'We sort it to get {cor}')\n",
    "positionscor = []\n",
    "for x in range(len(cor)):\n",
    "    positionscor.append(corrs.index(cor[x]))\n",
    "print(f'positionscor is {positionscor}')\n",
    "\n",
    "\n",
    "print(f'Original abso is {abso}')\n",
    "ab = sorted(abso)\n",
    "print(f'We sort it to get {ab}')\n",
    "positionsabs = []\n",
    "for x in range(len(ab)):\n",
    "    positionsabs.append(abso.index(ab[x]))\n",
    "positionsabs.reverse()\n",
    "print(f'positionsabs is {positionsabs}')\n",
    "\n",
    "\n",
    "print('$' * 50)\n",
    "finals = list()\n",
    "for k in range(len(ab)):\n",
    "    number_models = len(ab)\n",
    "    corspot = (positionscor.index(k) + 1)/ number_models\n",
    "    absspot = (positionsabs.index(k) + 1)/ number_models\n",
    "    metric = 0.5 * corspot / number_models + 0.5 * absspot / number_models\n",
    "    finals.append(metric)\n",
    "    print(f'the model is {k}, it holds position {positionscor.index(k)} in positionscor / {number_models}, and position {positionsabs.index(k)} in positionsabs / {number_models}. We weigh this as {0.5 * corspot / number_models} + {0.5 * absspot / number_models}')\n",
    "print(f'Finals is {finals}')\n",
    "sorted_finals = sorted(finals)\n",
    "print(f\"Sorted finals is {sorted_finals}\")\n",
    "print(f'The best model is {finals.index(sorted_finals[-1])}, followed by {finals.index(sorted_finals[-2])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores = []\n",
    "bestcor = 0.25 * positionsabs.index(positionscor[-1]) + (0.75 * len(ab))\n",
    "print(f'Our calculation is 0.25 * {positionsabs.index(positionscor[-1])} + 0.75 * {len(ab)}')\n",
    "print(f'Of course, positionsabs.index(positionscor[-1] is index {positionscor[-1]} of {positionsabs}')\n",
    "print(bestcor, 'for h5 file', positionscor[-1])\n",
    "scores.append(bestcor)\n",
    "secbestcor = 0.25 * positionsabs.index(positionscor[-2]) +( 0.75 *  len(ab) - 1)\n",
    "print(secbestcor, 'for h5 file', positionscor[-2])\n",
    "scores.append(secbestcor)\n",
    "thirdbestcor = 0.25 * positionsabs.index(positionscor[-3]) + (0.75 *  len(ab) - 2)\n",
    "print(thirdbestcor, 'for h5 file', positionscor[-3])\n",
    "scores.append(thirdbestcor)\n",
    "\n",
    "print('The best model is model #' +  str(positionscor[-1 * (1 + scores.index(max(scores)))]) + '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
